{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import math\n",
    "import json\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "model = \"gpt-4-0125-preview\"\n",
    "max_context_length = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file_path, chunk_size):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_name = file_name.lower()\n",
    "    if file_path:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(file_path, \"r\", encoding=\"utf-16-le\") as file:\n",
    "                text = file.read()\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "        num_tokens = len(encoding.encode(text))\n",
    "        if num_tokens > chunk_size:\n",
    "            if num_tokens > chunk_size:\n",
    "                split_size = math.ceil(num_tokens / chunk_size)\n",
    "                chunks = [\n",
    "                    text[i : i + chunk_size] for i in range(0, num_tokens, chunk_size)\n",
    "                ]\n",
    "                print(\"Text split into:\", split_size, \"chunks\")\n",
    "                return chunks, num_tokens, file_name, chunk_size\n",
    "            return text, num_tokens, file_name, chunk_size\n",
    "        else:\n",
    "            print(\"Reduce chunk size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_file(text, num_tokens):\n",
    "    if num_tokens > 4000:\n",
    "        num_tokens = 2000\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an assistant who extracts questions and the corresponding answers from texts to create a dataset for a machine learning model, you return only valid .json as well as all questions and answers in english.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'Create as many relevant questions and the corresponding answers for this text: {text}. Return each question-answer pair in the following format: {\"instruction\": <insert question here> , \"output\": <insert answer here>},',\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "        max_tokens=4000,\n",
    "        top_p=0.2,\n",
    "    )\n",
    "    response_ = response.choices[0].message.content\n",
    "    return response_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootDir = \"/Users/patrickmuller/Desktop/test_data\"\n",
    "file_paths = []\n",
    "output_file_name = \"V9\"\n",
    "\n",
    "for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "    for fname in fileList:\n",
    "        file_paths.append(os.path.join(dirName, fname))\n",
    "\n",
    "for file in file_paths:\n",
    "    text, num_tokens, file_name, max_context_length = load_file(file, 1000)\n",
    "    print(\"Total tokens in document:\", num_tokens)\n",
    "\n",
    "    if isinstance(text, list):\n",
    "        for t in text:\n",
    "            print(\"chunk length:\", len(t))\n",
    "            text = label_file(t, num_tokens)\n",
    "            with open(output_file_name + \".jsonl\", \"a\") as f:\n",
    "                f.write(text)\n",
    "    else:\n",
    "        text = label_file(text, num_tokens)\n",
    "        with open(output_file_name + \".jsonl\", \"a\") as f:\n",
    "            f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
