{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'lit-gpt (Python 3.10.0)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from openai import OpenAI\n",
    "import math\n",
    "import json\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'lit-gpt (Python 3.10.0)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def load_file(file_path, degree_level, degree_name):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_name = file_name.lower()\n",
    "    if file_path:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                text = file.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(file_path, \"r\", encoding=\"utf-16-le\") as file:\n",
    "                text = file.read()\n",
    "        encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-1106\")\n",
    "        num_tokens = len(encoding.encode(text))\n",
    "        if num_tokens > 15000:\n",
    "            number_of_needed_files = math.ceil(num_tokens / 4000)\n",
    "            chunk_size = math.ceil(num_tokens / number_of_needed_files)\n",
    "            chunks = [\n",
    "                text[i : i + chunk_size] for i in range(0, num_tokens, chunk_size)\n",
    "            ]\n",
    "            print(number_of_needed_files)\n",
    "            return chunks, num_tokens, file_name, degree_name, degree_level\n",
    "\n",
    "        return text, num_tokens, file_name, degree_name, degree_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'lit-gpt (Python 3.10.0)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "def label_file(text, num_tokens, degree_level, degree):\n",
    "    if num_tokens > 4000:\n",
    "        num_tokens = 2000\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-1106\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an assistant who extracts questions and the corresponding answers from texts to create a dataset for a machine learning model, you return only valid .jsonl as well as all questions and answers in english.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'Create as many relevant questions and the corresponding answers for this text: {text}. Return each question-answer pair in the following format: {{\"conversations\": [<insert question here> , <insert answer here>], \"source\":{degree_level+\"_\"+degree}}}',\n",
    "            },\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=num_tokens,\n",
    "        top_p=0.1,\n",
    "    )\n",
    "    response_ = response.choices[0].message.content\n",
    "    return response_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced_Systems_Design_(Systemtechnik)\n",
      "Master\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/.DS_Store\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/data_m_Advanced_Systems_Design_(Systemtechnik)_main_page.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/data_m_Advanced_Systems_Design_(Systemtechnik)_info_table.csv\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_Studium_Generale_Prozess_in_der_Fakult_t_Elektronik_und_Informatik.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_m_Advanced_Systems_Design_(Systemtechnik)_staff.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_Zeugn_Festl.Wahlf_30_MSD_20210426.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_PL_Anm_Wahlf_MSD_20200113-2.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_Ueberlassung_Geraete_EIN.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_pruefarb_anm_masterarb_MSD_210319.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_m_Advanced_Systems_Design_(Systemtechnik)_work.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_pruefarb_vereinb_nutz_abschlussarb_EIN_20210420.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_checkliste_master_immatrikulation.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_1510101_Sammelbogen_Master.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_pruefarb_verlaengerung_EIN_20210420.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_checkliste_bewerbung_master_msd.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/data_m_Advanced_Systems_Design_(Systemtechnik)_info_download_section.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_Canvas-Kurs_Informationen_Elektronik_Informatik.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_modulhandbuch-MSD-SPO-30.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_Antrag_auf_Zeugnis_EIN_230703.pdf.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/data_m_Advanced_Systems_Design_(Systemtechnik)_info.txt\n",
      "/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)/_pruefarb_anm_forscharb_MSD_20181206.pdf.txt\n",
      "3145\n",
      "412\n",
      "399\n",
      "331\n",
      "855\n",
      "280\n",
      "277\n",
      "922\n",
      "275\n",
      "35\n",
      "420\n",
      "627\n",
      "210\n",
      "269\n",
      "695\n",
      "1741\n",
      "500\n",
      "7333\n",
      "146\n",
      "770\n",
      "204\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory you want to start from\n",
    "rootDir = \"/Users/patrickmuller/Documents/dev/05_Project/01_data/m_Advanced_Systems_Design_(Systemtechnik)\"\n",
    "\n",
    "file_paths = []\n",
    "\n",
    "degree = os.path.basename(rootDir)\n",
    "\n",
    "if degree.startswith(\"b\"):\n",
    "    degree_level = \"Bachelor\"\n",
    "else:\n",
    "    degree_level = \"Master\"\n",
    "degree_name = degree[2:]\n",
    "\n",
    "print(degree_name)\n",
    "print(degree_level)\n",
    "\n",
    "for dirName, subdirList, fileList in os.walk(rootDir):\n",
    "    for fname in fileList:\n",
    "        # os.path.join() method in Python join one or more path components intelligently.\n",
    "        file_paths.append(os.path.join(dirName, fname))\n",
    "for f in file_paths:\n",
    "    print(f)\n",
    "for file in file_paths:\n",
    "    text, num_tokens, file_name, degree, degree_level = load_file(\n",
    "        file, degree_level, degree_name\n",
    "    )\n",
    "    print(num_tokens)\n",
    "    if num_tokens > 16000:\n",
    "        for t in text:\n",
    "            print(\"t:\", len(t))\n",
    "            text = label_file(t, num_tokens, degree, degree_level)\n",
    "    else:\n",
    "        text = label_file(text, num_tokens, degree, degree_level)\n",
    "\n",
    "    with open(degree + \"V2\" + \".jsonl\", \"a\") as f:\n",
    "        # Write the string to the file\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 3194 examples [00:00, 58920.11 examples/s]\n",
      "Generating test split: 11 examples [00:00, 5183.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# just for testing can be removed later\n",
    "# TODO was just for testing can be removed later\n",
    "from datasets import load_dataset\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "def format_dataset(\n",
    "    dataset_partition: dict, include_multi_turn_conversations: bool\n",
    ") -> List[dict]:\n",
    "    formatted_ds = []\n",
    "\n",
    "    for entry in dataset_partition:\n",
    "        convo = entry[\"conversations\"]\n",
    "        if include_multi_turn_conversations:\n",
    "            for i in range(0, len(convo) - 1, 2):\n",
    "                formatted_ds.append(\n",
    "                    {\"instruction\": convo[i], \"input\": \"\", \"output\": convo[i + 1]}\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            formatted_ds.append(\n",
    "                {\"instruction\": convo[0], \"input\": \"\", \"output\": convo[1]}\n",
    "            )\n",
    "\n",
    "    return formatted_ds\n",
    "\n",
    "\n",
    "dataset = load_dataset(\n",
    "    path=\"/Users/patrickmuller/Documents/dev/05_Project/02_code/dataset_converter\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "train_data = format_dataset(dataset[\"train\"], False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
