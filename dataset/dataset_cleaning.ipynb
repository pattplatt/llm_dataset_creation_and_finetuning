{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "filename = \"full_data_anonymized.jsonl\"  # replace with your filename\n",
    "seen_lines = set()\n",
    "duplicates = []\n",
    "\n",
    "with open(filename, \"r\") as f:\n",
    "    for line in f:\n",
    "        line_data = json.loads(line)  # convert JSON line to Python dict\n",
    "        line_tuple = tuple(\n",
    "            (k, tuple(v)) if isinstance(v, list) else (k, v)\n",
    "            for k, v in line_data.items()\n",
    "        )\n",
    "        if line_tuple in seen_lines:\n",
    "            duplicates.append(line_tuple)\n",
    "        else:\n",
    "            seen_lines.add(line_tuple)\n",
    "# Convert the dictionaries to strings before counting them\n",
    "duplicate_counter = Counter(json.dumps(d) for d in duplicates)\n",
    "# Count the occurrences of each duplicate\n",
    "\n",
    "# Convert the list of duplicates to a tuple\n",
    "output_filename = \"duplicates.jsonl\"  # replace with your output filename\n",
    "\n",
    "# Convert the tuple to a list of dictionaries\n",
    "duplicates_list = [dict(t) for t in duplicates]\n",
    "\n",
    "# Write each dictionary as a JSON line in the file\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    for duplicate in duplicates_list:\n",
    "        output_file.write(json.dumps(duplicate, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# Now, 'output.jsonl' contains the duplicates in JSONL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = \"full_data_anonymized.jsonl\"  # replace with your filename\n",
    "output_filename = \"output.jsonl\"  # replace with your output filename\n",
    "\n",
    "# Use a dictionary to count the occurrence of each line\n",
    "line_counts = {}\n",
    "\n",
    "# First pass: count the lines\n",
    "with open(filename, \"r\") as input_file:\n",
    "    for line in input_file:\n",
    "        line_data = json.loads(line)  # convert JSON line to Python dict\n",
    "        line_tuple = tuple(line_data[\"conversations\"])\n",
    "        if line_tuple in line_counts:\n",
    "            line_counts[line_tuple] += 1\n",
    "        else:\n",
    "            line_counts[line_tuple] = 1\n",
    "\n",
    "# Second pass: write the lines that only occur once to the output file\n",
    "with open(filename, \"r\") as input_file, open(output_filename, \"w\") as output_file:\n",
    "    for line in input_file:\n",
    "        line_data = json.loads(line)  # convert JSON line to Python dict\n",
    "        line_tuple = tuple(line_data[\"conversations\"])\n",
    "\n",
    "        if line_counts[line_tuple] == 1:\n",
    "            output_file.write(line)\n",
    "\n",
    "# Now, 'output.jsonl' is a copy of 'full_data_anonymized.jsonl' without the line to delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"full_dataset_anonym_cleaned.jsonl\"  # replace with your filename\n",
    "seen_lines = set()\n",
    "duplicates = []\n",
    "\n",
    "with open(filename, \"r\") as f:\n",
    "    for line in f:\n",
    "        line_data = json.loads(line)  # convert JSON line to Python dict\n",
    "        line_tuple = line_data[\"source\"]\n",
    "        if line_tuple in seen_lines:\n",
    "            duplicates.append(line_tuple)\n",
    "        else:\n",
    "            seen_lines.add(line_tuple)\n",
    "# Convert the dictionaries to strings before counting them\n",
    "duplicate_counter = Counter(json.dumps(d, ensure_ascii=False) for d in duplicates)\n",
    "# Count the occurrences of each duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"informatik_Master\" 277\n",
      "\"software_engineering_Bachelor\" 209\n",
      "\"elektrotechnik_Bachelor\" 206\n",
      "\"informatik_Bachelor\" 205\n",
      "\"data_science_Bachelor\" 202\n",
      "\"medien_informatik_Bachelor\" 189\n",
      "\"machine_learning_data_analytics_Master\" 175\n",
      "\"elektrotechnik_kompakt_Bachelor\" 171\n",
      "\"Technische_Informatik_Embedded Systems_Bachelor\" 162\n",
      "\"it_security_Bachelor\" 159\n",
      "\"Digital_Product_Design_and_Development_Bachelor\" 141\n",
      "\"Advanced_Systems_Design_(Systemtechnik)_Master\" 85\n",
      "\"Fakultät Elektronik und Informatik\" 30\n",
      "\"Sammelbogen Studium Generale / Sozialkompetenz\" 23\n",
      "\"Vereinbarung über Nutzungsrechte\" 9\n",
      "\"Studium_Generale_Process\" 7\n",
      "\"Vorlesungsplan Hochschule Aalen\" 6\n",
      "\"Sekretariat\" 5\n",
      "\"Hochschule Aalen\" 5\n",
      "\"Wahlfächer Fakultät EIN\" 3\n",
      "\"Begleitbogen Praxissemester\" 3\n",
      "\"Studium Generale Prozess\" 3\n",
      "\"Studium Generale Prozess in der Fakultät Elektronik und Informatik\" 3\n",
      "\"Veranstaltungen zu Berufsorientierung\" 2\n",
      "\"Sammelbogen Studium Generale / ehrenamtliche Tätigkeiten\" 1\n"
     ]
    }
   ],
   "source": [
    "for item, count in duplicate_counter.most_common():\n",
    "    print(item, count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lit-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
